{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAIG Introduction to Deep Learning Workshop - Solutions\n",
    "\n",
    "Today, we'll be exploring deep neural networks and applying them to the MNIST dataset.\n",
    "\n",
    "By Swetha Revanur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Environment\n",
    "\n",
    "Run any code below by highlighting the box and hitting `Shift + Enter`. Import the libraries below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter==1.0.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.3.1)\n",
      "Requirement already satisfied: torchtext==0.2.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (0.2.1)\n",
      "Requirement already satisfied: numpy==1.14.2 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (1.14.2)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (0.23.4)\n",
      "Requirement already satisfied: keras in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (2.2.4)\n",
      "Requirement already satisfied: theano in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (1.0.4)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (3.0.2)\n",
      "Requirement already satisfied: ipywidgets in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (7.4.2)\n",
      "Requirement already satisfied: jupyter-console in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.0.0)\n",
      "Requirement already satisfied: ipykernel in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.0)\n",
      "Requirement already satisfied: nbconvert in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (5.4.0)\n",
      "Requirement already satisfied: notebook in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (5.7.4)\n",
      "Requirement already satisfied: qtconsole in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (4.4.3)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from torch->-r requirements.txt (line 2)) (3.13)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from torchtext==0.2.1->-r requirements.txt (line 3)) (2.21.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from torchtext==0.2.1->-r requirements.txt (line 3)) (4.29.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from pandas->-r requirements.txt (line 5)) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from pandas->-r requirements.txt (line 5)) (2018.7)\n",
      "Requirement already satisfied: scipy>=0.14 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from keras->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from keras->-r requirements.txt (line 6)) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from keras->-r requirements.txt (line 6)) (1.0.5)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from keras->-r requirements.txt (line 6)) (1.0.6)\n",
      "Requirement already satisfied: h5py in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from keras->-r requirements.txt (line 6)) (2.9.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 8)) (2.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 8)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 8)) (1.0.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (7.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (4.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (4.3.2)\n",
      "Requirement already satisfied: pygments in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 1)) (2.3.1)\n",
      "Requirement already satisfied: jupyter-client in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 1)) (5.2.4)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: tornado>=4.2 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.1)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: testpath in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: defusedxml in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: bleach in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: jupyter-core in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (4.4.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (17.1.2)\n",
      "Requirement already satisfied: ipython-genutils in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (0.8.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prometheus-client in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from requests->torchtext==0.2.1->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from requests->torchtext==0.2.1->-r requirements.txt (line 3)) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from requests->torchtext==0.2.1->-r requirements.txt (line 3)) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from requests->torchtext==0.2.1->-r requirements.txt (line 3)) (2.8)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->-r requirements.txt (line 8)) (40.6.2)\n",
      "Requirement already satisfied: decorator in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (4.3.0)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (0.1.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (4.6.0)\n",
      "Requirement already satisfied: pickleshare in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.5)\n",
      "Requirement already satisfied: backcall in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (0.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (0.13.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (2.6.0)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from jinja2->nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: webencodings in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from terminado>=0.8.1->notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (0.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PYTHONHASHSEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 records in train set\n",
      "10000 records in test set\n",
      "70000 records in total\n",
      "\n",
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# load data from MNIST (70000 28x28 images total)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "num_train = x_train.shape[0]\n",
    "num_test = x_test.shape[0]\n",
    "\n",
    "print(num_train, 'records in train set')\n",
    "print(num_test, 'records in test set')\n",
    "print(num_train + num_test, 'records in total\\n')\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "dim = x_train.shape[1] # dimension of square images = 28\n",
    "\n",
    "# flatten so we instead have 70000 28^2=784-dimensional vectors (one per image)\n",
    "x_train = x_train.reshape((x_train.shape[0], dim*dim))\n",
    "x_test = x_test.reshape((x_test.shape[0], dim*dim))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train)) # 10 unique digits (0-9)\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Exercise 1: Create a Baseline Model\n",
    "\n",
    "**Your task:** At this point, we're ready to create a basic neural network classifier using Keras. Your model should have 6 layers, of sizes 10, 100, 500, 50, and `num_classes`. All layers, save the last one, should use a ReLU activation function. The last layer should use softmax. Check this [guide](https://keras.io/getting-started/sequential-model-guide/) out to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 15\n",
    "learning_rate = 5e-3\n",
    "\n",
    "#########################################################\n",
    "# Initializes baseline neural network.\n",
    "# ReLU and Softmax activations. Cross-entropy loss.\n",
    "#########################################################\n",
    "def baseline_classifier(learning_rate):\n",
    "    # create model\n",
    "    model_baseline = Sequential()\n",
    "\n",
    "    # YOUR CODE HERE:\n",
    "    model_baseline.add(Dense(10, input_dim = x_train.shape[1], activation = 'relu')) \n",
    "    model_baseline.add(Dense(100, activation = 'relu')) \n",
    "    model_baseline.add(Dense(500, activation = 'relu')) \n",
    "    model_baseline.add(Dense(100, activation = 'relu')) \n",
    "    model_baseline.add(Dense(50, activation = 'relu')) \n",
    "    model_baseline.add(Dense(num_classes, activation = 'softmax'))\n",
    "    # END CODE\n",
    "\n",
    "    # compile model\n",
    "    sgd = keras.optimizers.SGD(lr = learning_rate)\n",
    "    model_baseline.compile(loss = keras.losses.categorical_crossentropy, optimizer = sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Exercise 2: Train and Evaluate the Baseline Model\n",
    "\n",
    "**Your task:** Use the `eval()` function below to train and evaluate our baseline model. The return value of `eval()` is a tuple of loss and accuracy. Print both of these. In `eval()`, feel free to change the value of the `verbose` parameter. When `verbose = 0`, no information is printed. When it's 5, a lot of detailed information about the training process gets printed. Your test accuracy for this basic model should be around 37%.\n",
    "\n",
    "Note that a parameter is `model.fit()` is `validation_split`. This takes a float from 0 to 1, representing the percentage of the training set to use for validation. Why do we need a validation set? More than training performance, we are interested in how our model does on unseen data. We can split data into only training and test. But if we then optimize our model using results from the test set, our test set can no longer be considered unseen data. As a workaround, we split our dataset into train, validation, and test. This way, we can optimize on our validation set, and only touch our test set at the very end. For the purposes of this workshop, we have ignored the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 1s - loss: 1.7107 - acc: 0.4336\n",
      "Epoch 2/15\n",
      " - 1s - loss: 0.7817 - acc: 0.7421\n",
      "Epoch 3/15\n",
      " - 1s - loss: 0.5179 - acc: 0.8379\n",
      "Epoch 4/15\n",
      " - 1s - loss: 0.4323 - acc: 0.8650\n",
      "Epoch 5/15\n",
      " - 1s - loss: 0.3814 - acc: 0.8817\n",
      "Epoch 6/15\n",
      " - 1s - loss: 0.3473 - acc: 0.8928\n",
      "Epoch 7/15\n",
      " - 1s - loss: 0.3202 - acc: 0.9017\n",
      "Epoch 8/15\n",
      " - 1s - loss: 0.2990 - acc: 0.9084\n",
      "Epoch 9/15\n",
      " - 1s - loss: 0.2828 - acc: 0.9138\n",
      "Epoch 10/15\n",
      " - 1s - loss: 0.2688 - acc: 0.9185\n",
      "Epoch 11/15\n",
      " - 1s - loss: 0.2567 - acc: 0.9208\n",
      "Epoch 12/15\n",
      " - 1s - loss: 0.2463 - acc: 0.9245\n",
      "Epoch 13/15\n",
      " - 1s - loss: 0.2379 - acc: 0.9264\n",
      "Epoch 14/15\n",
      " - 1s - loss: 0.2298 - acc: 0.9289\n",
      "Epoch 15/15\n",
      " - 1s - loss: 0.2229 - acc: 0.9307\n",
      "10000/10000 [==============================] - 0s 11us/step\n",
      "\n",
      "\n",
      "Test loss: 0.2686284477956593\n",
      "Test accuracy: 0.9187\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "# Trains and evaluates given model. Returns loss and \n",
    "# accuracy.\n",
    "#########################################################\n",
    "def eval(model, verb = 2):\n",
    "    # fit the model\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs = epochs, \n",
    "              batch_size = batch_size, \n",
    "              verbose = verb,\n",
    "              shuffle = False)\n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(x_test, y_test)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "model_baseline = baseline_classifier(learning_rate)\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "loss, acc = eval(model_baseline)\n",
    "print('\\n\\nTest loss:', loss)\n",
    "print('Test accuracy:', acc)\n",
    "# END CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Exercise 3: Introduce Regularization\n",
    "\n",
    "Sometimes our train accuracies are consistently higher than our test accuracy.  We might also see train losses that continue to decrease while the validation losses hit a minimum then increase. Both of these things are indicators of overfitting and poor model generalization. Regularization is a way to fix this. Regularization reduces overfitting by adding a penalty to the loss function. By adding this penalty, the model is trained such that it does not learn interdependent sets of features weights.\n",
    "\n",
    "**Your task:** Add L2 regularization to the last two hidden layers of our model. You may want to refer to the [Keras documentation about regularizers](https://keras.io/regularizers/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 1s - loss: 14.6631 - acc: 0.5538\n",
      "Epoch 2/15\n",
      " - 1s - loss: 8.8709 - acc: 0.8135\n",
      "Epoch 3/15\n",
      " - 1s - loss: 5.6031 - acc: 0.8693\n",
      "Epoch 4/15\n",
      " - 1s - loss: 3.5970 - acc: 0.8914\n",
      "Epoch 5/15\n",
      " - 1s - loss: 2.3551 - acc: 0.9007\n",
      "Epoch 6/15\n",
      " - 1s - loss: 1.5806 - acc: 0.9079\n",
      "Epoch 7/15\n",
      " - 1s - loss: 1.0950 - acc: 0.9132\n",
      "Epoch 8/15\n",
      " - 1s - loss: 0.7905 - acc: 0.9175\n",
      "Epoch 9/15\n",
      " - 1s - loss: 0.5977 - acc: 0.9197\n",
      "Epoch 10/15\n",
      " - 1s - loss: 0.4755 - acc: 0.9228\n",
      "Epoch 11/15\n",
      " - 1s - loss: 0.3960 - acc: 0.9253\n",
      "Epoch 12/15\n",
      " - 1s - loss: 0.3446 - acc: 0.9266\n",
      "Epoch 13/15\n",
      " - 1s - loss: 0.3100 - acc: 0.9290\n",
      "Epoch 14/15\n",
      " - 1s - loss: 0.2867 - acc: 0.9309\n",
      "Epoch 15/15\n",
      " - 1s - loss: 0.2703 - acc: 0.9321\n",
      "10000/10000 [==============================] - 0s 15us/step\n",
      "\n",
      "\n",
      "Test loss: 0.2874129926919937\n",
      "Test accuracy: 0.9252\n"
     ]
    }
   ],
   "source": [
    "reg_strength = 0.1\n",
    "\n",
    "#########################################################\n",
    "# Initializes neural network with L2 regularization.\n",
    "#########################################################\n",
    "def regularized_classifier(learning_rate, reg_strength):\n",
    "    # create model\n",
    "    model_regularized = Sequential()\n",
    "\n",
    "    # YOUR CODE HERE:\n",
    "    model_regularized.add(Dense(10, input_dim = dim*dim, activation = 'relu')) \n",
    "    model_regularized.add(Dense(100, activation = 'relu')) \n",
    "    model_regularized.add(Dense(500, activation = 'relu', kernel_regularizer = regularizers.l2(reg_strength))) \n",
    "    model_regularized.add(Dense(100, activation = 'relu'))\n",
    "    model_regularized.add(Dense(50, activation = 'relu'))\n",
    "    model_regularized.add(Dense(num_classes, activation = 'softmax'))\n",
    "    # END CODE\n",
    "    \n",
    "    # compile model\n",
    "    sgd = keras.optimizers.SGD(lr = learning_rate)\n",
    "    model_regularized.compile(loss = keras.losses.categorical_crossentropy, \n",
    "                  optimizer = sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model_regularized\n",
    "\n",
    "model_regularized = regularized_classifier(learning_rate, reg_strength)\n",
    "\n",
    "loss, acc = eval(model_regularized)\n",
    "print('\\n\\nTest loss:', loss)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Exercise 4: Introduce Dropout\n",
    "\n",
    "Dropout is another regularization technique to prevent overfitting. Dropout randomly selects neurons to ignore during training. In other words, they are “dropped-out” randomly. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass. \n",
    "\n",
    "**Your task:** Remove the regularization, and this time around, add dropout for the input layer. You may want to refer to the [Keras documentation about Dropout layer](https://keras.io/layers/core/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 1s - loss: 1.6247 - acc: 0.4556\n",
      "Epoch 2/15\n",
      " - 1s - loss: 0.7926 - acc: 0.7323\n",
      "Epoch 3/15\n",
      " - 1s - loss: 0.5507 - acc: 0.8206\n",
      "Epoch 4/15\n",
      " - 1s - loss: 0.4452 - acc: 0.8599\n",
      "Epoch 5/15\n",
      " - 2s - loss: 0.3882 - acc: 0.8792\n",
      "Epoch 6/15\n",
      " - 2s - loss: 0.3554 - acc: 0.8906\n",
      "Epoch 7/15\n",
      " - 2s - loss: 0.3327 - acc: 0.8966\n",
      "Epoch 8/15\n",
      " - 1s - loss: 0.3162 - acc: 0.9017\n",
      "Epoch 9/15\n",
      " - 2s - loss: 0.2964 - acc: 0.9079\n",
      "Epoch 10/15\n",
      " - 1s - loss: 0.2819 - acc: 0.9130\n",
      "Epoch 11/15\n",
      " - 2s - loss: 0.2743 - acc: 0.9145\n",
      "Epoch 12/15\n",
      " - 2s - loss: 0.2606 - acc: 0.9193\n",
      "Epoch 13/15\n",
      " - 2s - loss: 0.2557 - acc: 0.9210\n",
      "Epoch 14/15\n",
      " - 1s - loss: 0.2449 - acc: 0.9235\n",
      "Epoch 15/15\n",
      " - 1s - loss: 0.2373 - acc: 0.9265\n",
      "10000/10000 [==============================] - 0s 27us/step\n",
      "\n",
      "\n",
      "Test loss: 0.22514843581169844\n",
      "Test accuracy: 0.9318\n"
     ]
    }
   ],
   "source": [
    "dropout_strength = 0.1\n",
    "\n",
    "#########################################################\n",
    "# Initializes neural network with dropout.\n",
    "#########################################################\n",
    "def dropout_classifier(learning_rate, dropout_strength):\n",
    "    # create model\n",
    "    model_dropout = Sequential()\n",
    "\n",
    "    # YOUR CODE HERE:\n",
    "    model_dropout.add(Dropout(dropout_strength, input_shape = (dim*dim,)))\n",
    "    model_dropout.add(Dense(10, activation = 'relu')) \n",
    "    model_dropout.add(Dense(100, activation = 'relu')) \n",
    "    model_dropout.add(Dense(500, activation = 'relu')) \n",
    "    model_dropout.add(Dense(100, activation = 'relu')) \n",
    "    model_dropout.add(Dense(50, activation = 'relu')) \n",
    "    model_dropout.add(Dense(num_classes, activation = 'softmax'))\n",
    "    # END CODE\n",
    "    \n",
    "    # compile model\n",
    "    sgd = keras.optimizers.SGD(lr = learning_rate)\n",
    "    model_dropout.compile(loss = keras.losses.categorical_crossentropy, \n",
    "                  optimizer = sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model_dropout\n",
    "\n",
    "model_dropout = dropout_classifier(learning_rate, dropout_strength)\n",
    "\n",
    "loss, acc = eval(model_dropout, verb = 2)\n",
    "print('\\n\\nTest loss:', loss)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
